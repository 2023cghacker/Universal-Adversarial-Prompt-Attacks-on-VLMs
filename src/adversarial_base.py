import torch
import torch.nn.functional as F
from PIL import Image
from transformers import CLIPModel, CLIPProcessor
import os
import sys
from torchvision import transforms
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import sys


class CLIPAdversarialBase:
    def __init__(self, model_path, device=None, num_steps=300, lr=1e-3):
        """
        å¯¹æŠ—è®­ç»ƒåŸºç±»ï¼šå°è£…å…¬å…±åŠŸèƒ½ï¼ˆæ¨¡å‹åŠ è½½ã€é¢„å¤„ç†ã€ä¿å­˜ç­‰ï¼‰
        :param model_path: CLIPæ¨¡å‹æœ¬åœ°è·¯å¾„
        :param device: è®¡ç®—è®¾å¤‡ï¼ˆè‡ªåŠ¨é€‰æ‹©cuda/cpuï¼‰
        :param num_steps: è®­ç»ƒæ­¥æ•°
        :param lr: å­¦ä¹ ç‡
        """
        # è®¾å¤‡é…ç½®
        self.device = (
            device if device else ("cuda" if torch.cuda.is_available() else "cpu")
        )
        self.num_steps = num_steps
        self.lr = lr

        # è¾“å‡ºç›®å½•ä¸æ—¶é—´æˆ³ï¼ˆæ‰€æœ‰å­ç±»å…±äº«ï¼‰
        self.timestamp = datetime.now().strftime("%m%d_%H%M%S")
        self.output_dir = os.path.join("output", self.timestamp)
        os.makedirs(self.output_dir, exist_ok=True)
        print(f"è¾“å‡ºæ–‡ä»¶ä¿å­˜è·¯å¾„: {self.output_dir}")

        # åŠ è½½CLIPæ¨¡å‹ä¸å¤„ç†å™¨
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        self.model = CLIPModel.from_pretrained(model_path).to(self.device).eval()
        self.processor = CLIPProcessor.from_pretrained(model_path)

        # CLIPé»˜è®¤å›¾åƒæ ‡å‡†åŒ–å‚æ•°ï¼ˆImageNetï¼‰
        self.mean = torch.tensor([0.48145466, 0.4578275, 0.40821073]).view(1, 3, 1, 1)
        self.std = torch.tensor([0.26862954,0.26130258, 0.27577711]).view(1, 3, 1, 1)

    def load_and_preprocess_image(self, image_path):
        """å…¬å…±æ–¹æ³•ï¼šåŠ è½½å¹¶é¢„å¤„ç†å•å¼ å›¾åƒï¼ˆè¿”å›å¼ é‡ä¸åŸå§‹å›¾åƒï¼‰"""
        raw_img = Image.open(image_path).convert("RGB")
        image_inputs = self.processor(images=raw_img, return_tensors="pt")[
            "pixel_values"
        ].to(self.device)
        return image_inputs.clone().detach(), raw_img

    def get_target_text_embedding(self, target_text):
        """å…¬å…±æ–¹æ³•ï¼šè·å–ç›®æ ‡æ–‡æœ¬çš„å½’ä¸€åŒ–åµŒå…¥"""
        with torch.no_grad():
            text_inputs = self.processor(
                text=[target_text], return_tensors="pt", padding=True
            ).to(self.device)
            target_emb = self.model.get_text_features(**text_inputs)
            return F.normalize(target_emb, dim=-1)

    def get_target_image_embedding(self, target_img_path):
        """å…¬å…±æ–¹æ³•ï¼šè·å–ç›®æ ‡å›¾åƒçš„å½’ä¸€åŒ–åµŒå…¥"""
        with torch.no_grad():
            img_tensor, _ = self.load_and_preprocess_image(target_img_path)
            target_emb = self.model.get_image_features(pixel_values=img_tensor)
            return F.normalize(target_emb, dim=-1)

    def _denormalize(self, tensor):
        """å†…éƒ¨å…¬å…±æ–¹æ³•ï¼šå°†æ ‡å‡†åŒ–å¼ é‡åè½¬ä¸º0-255å›¾åƒæ ¼å¼"""
        mean = self.mean.to(tensor.device)
        std = self.std.to(tensor.device)
        tensor = tensor * std + mean
        return torch.clamp(tensor * 255.0, 0, 255).byte()

    def save_adversarial_image(
            self,
            img_tensors,
            base_names,
            patch=None,
            patch_size=80,
            positions=None,
            save_suffix=".png",  # å¼ºåˆ¶é»˜è®¤ç”¨PNGï¼ˆæ— æŸæ ¼å¼ï¼‰
        ):
        """
        å…¬å…±æ–¹æ³•ï¼šæ‰¹é‡ä¿å­˜å¯¹æŠ—å›¾åƒï¼ˆæ”¯æŒå•patch+å¤šèƒŒæ™¯å›¾ï¼‰- æ— æŸç‰ˆæœ¬
        æ ¸å¿ƒï¼šæ— å‹ç¼©PNGä¿å­˜ + åå½’ä¸€åŒ–é€»è¾‘ä¸é¢„å¤„ç†å®Œå…¨å¯¹é½
        """
        # è¾“å…¥åˆæ³•æ€§æ ¡éªŒ
        if len(img_tensors) != len(base_names):
            raise ValueError("å›¾åƒå¼ é‡åˆ—è¡¨ä¸åŸºç¡€åç§°åˆ—è¡¨é•¿åº¦å¿…é¡»ä¸€è‡´")
        if positions is not None and len(img_tensors) != len(positions):
            raise ValueError("å›¾åƒå¼ é‡åˆ—è¡¨ä¸ä½ç½®åˆ—è¡¨é•¿åº¦å¿…é¡»ä¸€è‡´")
        # å¼ºåˆ¶æ ¡éªŒæ ¼å¼ï¼šä»…å…è®¸PNGï¼ˆå…¶ä»–æ ¼å¼å¦‚JPGä¸ºæœ‰æŸï¼Œä¸æ”¯æŒæ— æŸä¿å­˜ï¼‰
        if save_suffix.lower() != ".png":
            raise ValueError("æ— æŸä¿å­˜ä»…æ”¯æŒPNGæ ¼å¼ï¼Œè¯·å°†save_suffixè®¾ä¸º'.png'")

        saved_paths = []

        # ---------------------- 1. æ— æŸä¿å­˜è¡¥ä¸ï¼ˆä»…1æ¬¡ï¼‰----------------------
        if patch is not None:
            # åå½’ä¸€åŒ–ï¼šæ¢å¤ä¸º0~255èŒƒå›´ï¼ˆä¸å›¾åƒé¢„å¤„ç†åå‘ï¼‰
            patch_denorm = self._denormalize(patch.clone())
            # å¼ é‡â†’numpyï¼šæ³¨æ„æ•°æ®ç±»å‹è½¬æ¢ï¼ˆuint8æ˜¯å›¾åƒæ ‡å‡†æ ¼å¼ï¼Œé¿å…å¤±çœŸï¼‰
            patch_np = (
                patch_denorm.squeeze()  # ç§»é™¤æ‰¹æ¬¡ç»´åº¦ (1,3,H,W) â†’ (3,H,W)
                .cpu()  # è½¬ç§»åˆ°CPUï¼ˆnumpyä¸æ”¯æŒCUDAå¼ é‡ï¼‰
                .permute(1, 2, 0)  # ç»´åº¦è½¬ç½® (3,H,W) â†’ (H,W,3)ï¼ˆç¬¦åˆPILå›¾åƒæ ¼å¼ï¼‰
                .numpy()
                .astype(np.uint8)  # è½¬ä¸º8ä½æ— ç¬¦å·æ•´æ•°ï¼ˆå›¾åƒåƒç´ æ ‡å‡†ï¼‰
            )
            # æ— å‹ç¼©ä¿å­˜PNGï¼ˆcompress_level=0è¡¨ç¤ºå®Œå…¨æ— æŸï¼Œæ— ä»»ä½•å‹ç¼©ï¼‰
            patch_path = os.path.join(
                self.output_dir, f"patch_{self.timestamp}{save_suffix}"
            )
            Image.fromarray(patch_np).save(patch_path, format="PNG", compress_level=0)
            # print(f"âœ… æ— æŸä¿å­˜è¡¥ä¸: {patch_path}")

        # ---------------------- 2. æ‰¹é‡æ— æŸä¿å­˜å¯¹æŠ—å›¾åƒ ----------------------
        for i, (img_tensor, base_name) in enumerate(zip(img_tensors, base_names)):
            final_img = img_tensor.clone()  # å¤åˆ¶å¼ é‡ï¼Œé¿å…ä¿®æ”¹åŸæ•°æ®

            # åº”ç”¨è¡¥ä¸ï¼ˆè‹¥æä¾›ï¼‰ï¼šä¸è®­ç»ƒæ—¶å åŠ é€»è¾‘å®Œå…¨ä¸€è‡´
            if patch is not None and positions is not None:
                x, y = positions[i]
                # ç¡®ä¿è¡¥ä¸ä¸å›¾åƒå¼ é‡è®¾å¤‡ä¸€è‡´
                final_img[:, :, y:y+patch_size, x:x+patch_size] = patch.to(final_img.device)

            # æ‰“å°ã€è®­ç»ƒæ—¶çš„å¯¹æŠ—å¼ é‡ã€‘ä¿¡æ¯ï¼ˆå…³é”®å¯¹æ¯”åŸºå‡†ï¼‰
            # print(f"\n===== ä¿å­˜å‰ - å¯¹æŠ—å¼ é‡ {i} ä¿¡æ¯ =====")
            # print(f"è®­ç»ƒæ—¶å¼ é‡å½¢çŠ¶: {final_img.shape}")
            # print(f"è®­ç»ƒæ—¶å¼ é‡è®¾å¤‡: {final_img.device}")
            # print(f"è®­ç»ƒæ—¶å¼ é‡èŒƒå›´: [{final_img.min().item():.6f}, {final_img.max().item():.6f}]")
            # print(f"è®­ç»ƒæ—¶å¼ é‡å‰3ä¸ªå€¼: {final_img.flatten()[:3].cpu().numpy()}")  # æ‰“å°å‰3ä¸ªå…ƒç´ 
        

            # å…³é”®æ­¥éª¤ï¼šåå½’ä¸€åŒ– + å¼ é‡â†’å›¾åƒè½¬æ¢ï¼ˆæ— å¤±çœŸï¼‰
            final_denorm = self._denormalize(final_img.clone())  # åå½’ä¸€åŒ–åˆ°0~255
            
            final_np = (
                final_denorm.squeeze()
                .cpu()
                .permute(1, 2, 0)
                .numpy()
                .astype(np.uint8)  # å¿…é¡»ç”¨uint8ï¼Œå¦åˆ™PILä¿å­˜æ—¶ä¼šè‡ªåŠ¨æˆªæ–­å¯¼è‡´å¤±çœŸ
            )

            # æ— å‹ç¼©ä¿å­˜PNG
            save_path = os.path.join(
                self.output_dir, f"{base_name}_{self.timestamp}{save_suffix}"
            )
            Image.fromarray(final_np).save(save_path, format="PNG", compress_level=0)
            saved_paths.append(save_path)

        # print(f"âœ… å·²æ— æŸä¿å­˜ {len(saved_paths)} å¼ å¯¹æŠ—å›¾åƒï¼ˆæ— å‹ç¼©PNGï¼‰")
        return saved_paths
    # def save_adversarial_image(
    #     self,
    #     img_tensors,
    #     base_names,
    #     patch=None,
    #     patch_size=80,
    #     positions=None,
    #     save_suffix=".png",
    # ):
    #     """å…¬å…±æ–¹æ³•ï¼šæ‰¹é‡ä¿å­˜å¯¹æŠ—å›¾åƒï¼ˆæ”¯æŒå•patch+å¤šèƒŒæ™¯å›¾ï¼‰"""
    #     # è¾“å…¥åˆæ³•æ€§æ ¡éªŒ
    #     if len(img_tensors) != len(base_names):
    #         raise ValueError("å›¾åƒå¼ é‡åˆ—è¡¨ä¸åŸºç¡€åç§°åˆ—è¡¨é•¿åº¦å¿…é¡»ä¸€è‡´")
    #     if positions is not None and len(img_tensors) != len(positions):
    #         raise ValueError("å›¾åƒå¼ é‡åˆ—è¡¨ä¸ä½ç½®åˆ—è¡¨é•¿åº¦å¿…é¡»ä¸€è‡´")

    #     saved_paths = []

    #     # ä¿å­˜è¡¥ä¸ï¼ˆä»…ä¿å­˜1æ¬¡ï¼‰
    #     if patch is not None:
    #         patch_denorm = self._denormalize(patch.clone())
    #         patch_np = (
    #             patch_denorm.squeeze().cpu().permute(1, 2, 0).numpy().astype(np.uint8)
    #         )
    #         patch_path = os.path.join(
    #             self.output_dir, f"patch_{self.timestamp}{save_suffix}"
    #         )
    #         Image.fromarray(patch_np).save(patch_path)

    #     # æ‰¹é‡ä¿å­˜èƒŒæ™¯å›¾åƒï¼ˆå«è¡¥ä¸åº”ç”¨ï¼‰
    #     for i, (img_tensor, base_name) in enumerate(zip(img_tensors, base_names)):
    #         final_img = img_tensor.clone()
    #         # åº”ç”¨è¡¥ä¸ï¼ˆè‹¥æä¾›ï¼‰
    #         if patch is not None and positions is not None:
    #             x, y = positions[i]
    #             final_img[:, :, y : y + patch_size, x : x + patch_size] = patch

    #         # è½¬æ¢ä¸ºPILå›¾åƒå¹¶ä¿å­˜
    #         final_denorm = self._denormalize(final_img.clone())
    #         final_np = (
    #             final_denorm.squeeze().cpu().permute(1, 2, 0).numpy().astype(np.uint8)
    #         )
    #         save_path = os.path.join(
    #             self.output_dir, f"{base_name}_{self.timestamp}{save_suffix}"
    #         )
    #         Image.fromarray(final_np).save(save_path)
    #         saved_paths.append(save_path)

    #     # print(f"âœ… å·²ä¿å­˜ {len(saved_paths)} å¼ å¯¹æŠ—å›¾åƒ")
    #     return saved_paths

    def test(self, img_path, target_text=None, target_img=None):
        """å…¬å…±æ–¹æ³•ï¼šæµ‹è¯•å›¾åƒä¸ç›®æ ‡ï¼ˆæ–‡æœ¬/å›¾åƒï¼‰çš„ä½™å¼¦ç›¸ä¼¼åº¦"""

        # è®¡ç®—å›¾åƒåµŒå…¥ä¸ç›®æ ‡åµŒå…¥
        img_tensor, _ = self.load_and_preprocess_image(img_path)
        # æ‰“å°ã€åŠ è½½åã€‘çš„å¼ é‡ä¿¡æ¯ï¼ˆä¸è®­ç»ƒæ—¶å¯¹æ¯”ï¼‰
        # print(f"\n===== åŠ è½½å - å›¾åƒå¼ é‡ä¿¡æ¯ =====")
        # print(f"åŠ è½½åå¼ é‡å½¢çŠ¶: {img_tensor.shape}")
        # print(f"åŠ è½½åå¼ é‡èŒƒå›´: [{img_tensor.min().item():.6f}, {img_tensor.max().item():.6f}]")
        # print(f"åŠ è½½åå¼ é‡å‰3ä¸ªå€¼: {img_tensor.flatten()[:3].cpu().numpy()}")  # æ‰“å°å‰3ä¸ªå…ƒç´ 
        
        if target_text is not None:
            target_emb = self.get_target_text_embedding(target_text)
            target_info = f"'{target_text}'"
        else:
            target_emb = self.get_target_image_embedding(target_img)
            target_info = f"'{target_img}'"

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        with torch.no_grad():
            img_emb = self.model.get_image_features(pixel_values=img_tensor)
            img_emb = F.normalize(img_emb, dim=-1)
            similarity = F.cosine_similarity(img_emb, target_emb).mean()

        print(f"ğŸ“Š ç›®æ ‡{target_info}ä¸å›¾åƒçš„ä½™å¼¦ç›¸ä¼¼åº¦: {similarity.item():.6f}")
        return similarity.item()

    @staticmethod
    def _format_timedelta(td):
        """å†…éƒ¨é™æ€æ–¹æ³•ï¼šæ ¼å¼åŒ–æ—¶é—´ï¼ˆXh Ym Zsï¼‰"""
        total_sec = int(td.total_seconds())
        hours, rem = divmod(total_sec, 3600)
        minutes, seconds = divmod(rem, 60)
        return f"{hours}h {minutes}m {seconds}s"
