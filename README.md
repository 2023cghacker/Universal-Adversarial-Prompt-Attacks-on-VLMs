# Universal-Adversarial-Prompt-Attacks-on-Large-Language-Models
This project explores universal adversarial attacks on large language models (LLMs) by optimizing prompt suffixes to induce targeted misbehavior. 
